---
title: "Really 600k ways of PTSD"
author: "Or Duek & Tobias Spiller"
output:
  html_document:
    df_print: paged
---

## This work intends to adress 
- https://journals.sagepub.com/doi/10.1177/1745691613504115

- We will take a look at the DSM-5 data sets we have to see number of combination of symptoms of PTSD in DSM-V. 
- We could also look at the previous dataset of DSM-IV (150k patients) to see number of combinations there and compare the two
- Should take a look at somewhat similar work done in depression by Eiko Fried here: https://www.sciencedirect.com/science/article/pii/S0165032714006326?via%3Dihub


```{r}
## load libraries
require(foreign)
require(tidyverse)
require(bootnet)
require(qgraph)
library(BGGM)
library(GGMnonreg)
require(mgm)
require(EGAnet)
require(lavaan)
require(psychonetrics)
```

```{r}
# read dataset
df <- read.spss('/home/or/Documents/va_dsm5_data/PCL FY15-16.sav', to.data.frame = TRUE)
```

#### Organise the data a bit
- Number of NAs
- Plot histograms of pcl score and age

```{r organize}
# check nas
# calculate PCL5 scores A27-A46
df$totalPCL <- rowSums(df[21:40])
#hist(df$totalPCL)
sum(is.na(df$totalPCL))

df_clean <- filter(df, !is.na(df$totalPCL))
hist(df_clean$totalPCL)
hist(df_clean$Age)
```

#### Now we need to binaries the PCL symtpoms to 0 (no symptoms) or more than zero - for each pcl item

```{r}
# making sure the count procedure works as expected
id <- c(1,2,3,4)
a <-  c("a","b","a","b")
b <-  c("a","a","a","b")
c <-  c("b","b","b","a")

test <- data.frame(id,a,b,c)
test$id <- as.factor(test$id)
# count combinations
plyr::count(test[, -1])
```
### Create dataframe of PCL and id only - but with binary PCL scores
```{r}
## PCL is a27 - a46 (PCL-5)

for (i in 27:46){
  nam <- paste("A", i, sep = "")
  pcl <- paste("PCL", i-26, sep = "")
  df_clean[pcl] <- dplyr::case_when(df_clean[nam]==0 ~ 'NO', df_clean[nam]>0 ~ 'YES')
  #print(nam)
  #print(pcl)
}
```

#### Now lets count combinations
```{r}
# create specific dataframe
dfBinary <- data_frame(df_clean$IDNUM, df_clean[92:111])
countFreq <- plyr::count(dfBinary[, -1])
```

```{r}
## count how many with only one
sum(countFreq$freq==1)
# count more than one less than ten
sum(countFreq$freq<10) - sum(countFreq$freq==1)
4702 / nrow(dfBinary)
```

### Number of combinations
So, we have a total of 474 combinations observed in this dataset. With 349 combinations have only one individual. 96 combinations had less than 10 individuals (but more than one). One combination had 4702 individuals (62.2%). 

### Let us test with binary of pcl=>2 as yes and else is no (moderate symptoms)

```{r}
dfClean2 <- df_clean
for (i in 27:46){
  nam <- paste("A", i, sep = "")
  pcl <- paste("PCL", i-26, sep = "")
  dfClean2[pcl] <- dplyr::case_when(dfClean2[nam]<=1 ~ 'NO', dfClean2[nam]>=2 ~ 'YES')
 
}
```

### Check combinations

```{r}
# create specific dataframe
dfBinary2 <- data_frame(dfClean2$IDNUM, dfClean2[92:111])
countFreq2 <- plyr::count(dfBinary2[, -1])
```

### This creates more combinations (1650)

```{r}
## count how many with only one
sum(countFreq2$freq==1)
# count more than one less than ten
sum(countFreq2$freq<10) - sum(countFreq2$freq==1)
max(countFreq2$freq)
2473 / nrow(dfBinary2)
```

1339 of the combination have only one individual. 
258 are less than 10 individuals but more than one.
2473 (32.7%) have same combination, which is the most prevalent in the dataset.

## Now we will do the same procedure on a second (smaller) DSM5 dataset

```{r}
df_new <- read.spss('/home/or/Documents/va_dsm5_data/psf19pcl.sav', to.data.frame = TRUE)
df_new$totalPCL <- rowSums(df_new[7:26])

df_newClean <- filter(df_new, !is.na(df_new$totalPCL))
hist(df_newClean$totalPCL)
summary(df_newClean$AGE_OCT01)
```
### We have 6656 valid observations. 
- Lets binarize using same method and count combinations

```{r}
for (i in 1:20){
  # becuase under 10 its PCLN01 (02,03) need to add zero so run if
  if (i<10){
  nam <- paste("PCLN0", i, sep = "")  
  }
  else {
    nam <- paste("PCLN", i, sep = "")
  }
  pcl <- paste("PCL", i, sep = "")
  df_newClean[pcl] <- dplyr::case_when(df_newClean[nam]==0 ~ 'NO', df_newClean[nam]>0 ~ 'YES')
  
}
```

### Create data frame

```{r}
# create specific dataframe
dfNew_Binary <- data_frame(df_newClean$ID, df_newClean[63:82])
countFreq_new <- plyr::count(dfNew_Binary[, -1])
```

### Only 177 possible combinations. 

```{r}
## count how many with only one
sum(countFreq_new$freq==1)
# count more than one less than ten
sum(countFreq_new$freq<10) - sum(countFreq_new$freq==1)
max(countFreq_new$freq)
6295 / nrow(dfNew_Binary)
```
- 94% (6295) are same combination

## something is a bit weird, lets make sure no NAs are hiding there
```{r}
table(is.na(df_newClean$PCLN01))
```
- Ok, everything is ok. 
Lets use the second binarized option (2 and more), and see how many combinations we get

```{r}
df_newClean2 <- df_newClean
for (i in 1:20){
  # becuase under 10 its PCLN01 (02,03) need to add zero so run if
  if (i<10){
  nam <- paste("PCLN0", i, sep = "")  
  }
  else {
    nam <- paste("PCLN", i, sep = "")
  }
  pcl <- paste("PCL", i, sep = "")
  df_newClean2[pcl] <- dplyr::case_when(df_newClean2[nam]<=1 ~ 'NO', df_newClean2[nam]>=2 ~ 'YES')
  
}
```

```{r}
# create specific dataframe
dfNew_Binary2 <- data_frame(df_newClean2$ID, df_newClean2[63:82])
countFreq_new2 <- plyr::count(dfNew_Binary2[, -1])
```

### Total of 1153 combinations. Lets look into them more carefully

```{r}
## count how many with only one
sum(countFreq_new2$freq==1)
# count more than one less than ten
sum(countFreq_new2$freq<10) - sum(countFreq_new2$freq==1)
max(countFreq_new2$freq)
2858 / nrow(dfNew_Binary2)
```

### Some data on the combinations
- 904 of the 1153 have only one individual. 
- 208 have more than one but less than 10 individuals
- 2858 individuals are in the most prevalent combination (43%)


### Lets add DSM-IV to the analysis (using data from previous study published in ...)

```{r}
# load data set
source('/home/or/Documents/va_data/readData.r')
```

```{r}
# all patientes with PTSD and PCLTOT
pclAll <- dplyr::filter(vaDatclean, !is.na(BPCLTOT))
# plot pcl total score 
hist(pclAll$BPCLTOT)
# we have a minimum of 2 - so we have some NAs - let remove them
pclAll_Nas <- filter(pclAll, BPCLTOT <=16)
# total of 20 subjects with 16 or less in PCL (i.e. at least one missing variable)
# we can remove them from analysis
pclAll <- filter(pclAll, BPCLTOT >=17)
# 159577 patients
#pclNetwork <- pclNoNa # just medicated
pclNetwork <- pclAll
nrow(pclNetwork)
hist(pclNetwork$BPCLTOT)
```

```{r}
# take just pcl
pclItems <- dplyr::select(pclAll, starts_with("PCL"))
pclItems_noCluster <- dplyr::select(pclItems, -PCLFY, -PCLSURVEYDATE, -PCLRAWSCORE)
nrow(pclItems_noCluster)
pclItems_noCluster <- na.omit(pclItems_noCluster)
nrow(pclItems_noCluster)
```

Total of 158,139 patients with valid PCL-4 scores (PCL-M)
Now we can run the analysis similar to before (binarize and count combinations)

```{r}
dfPCL4 <- pclItems_noCluster
# using PCL-4 recommended threshold is 3+ (not 2+ as in PCL5)
for (i in 1:17){
  nam = paste("PCL", i, sep = "")
  pcl <- paste("PCLB", i, sep = "")
  dfPCL4[pcl] <- dplyr::case_when(dfPCL4[nam]<=2 ~ 'NO', dfPCL4[nam]>=3 ~ 'YES')
  
}
```

```{r}
# create specific dataframe
id = 1:nrow(dfPCL4)
dfPCL4_Binary <- data_frame(id, dfPCL4[18:34])
countFreq_pcl4 <- plyr::count(dfPCL4_Binary[,-1])
```

### OK - so number of combinations is 25,253 total
- Lets look at the results a bit

```{r}
## count how many with only one
sum(countFreq_pcl4$freq==1)
# percentage
sum(countFreq_pcl4$freq==1) / nrow(countFreq_pcl4)
# count more than one less than ten
sum(countFreq_pcl4$freq<10) - sum(countFreq_pcl4$freq==1)
max(countFreq_pcl4$freq)
max(countFreq_pcl4$freq) / nrow(dfPCL4_Binary)
```

### Sum results
- 15,479 combinations are with only 1 individual (59% of combinations)
- 9368 are less than 10 individuals but more than one
- 28,901 individuals are present in the most frequent combination of symptoms (18% of patients)


### Last thing - lets randomly sample 7k people, to see how it affects the number of combinations

```{r}
# sample
#pcl4Sample <- sample(dfPCL4_Binary, size = 7000)
picked = sample(seq_len(nrow(dfPCL4_Binary)),size = 7000)
pcl4Sample <- dfPCL4_Binary[picked,]
countFreq_pcl4Samples <- plyr::count(pcl4Sample[,-1])
```

### Results of sampling:

Now we have only 2813 combinations. So the size of dataset definetly affects number of possible combinations. BUT - it is also important to state that while DSM-5 has app. 600k combinations, DSM-IV has around 70K and even with a large sample size of 150k patients, we have found a maximum of 28k combinations, which is less than half of possible combinations. 


### Last play with data - loop through randomization and print how many combination we get with 7k patients.
```{r}
# sample
#pcl4Sample <- sample(dfPCL4_Binary, size = 7000)
x <- 1:1000
for (i in 1:1000){
  picked = sample(seq_len(nrow(dfPCL4_Binary)),size = 7000)
  pcl4Sample <- dfPCL4_Binary[picked,]
  countFreq_pcl4Samples <- plyr::count(pcl4Sample[,-1])
  x[i] <- nrow(countFreq_pcl4Samples)
}

MASS::truehist(x)
```
### Summary
- DSM-IV with large dataset (150k) shows a 26,253 combinations
- DSM-IV with randomly sampled smaller sets (7k) shows around 2800 combinations
- DSM-V shows 1650 (sample 1) and 1153 (sample 2) combinations
- Interestingly, DSM-IV shows more actual combination of symptoms, even when accounting for sample size


* so - sample size indeed affects the number of actual combinations, but even when accounting for sample size we still see much lower numbers compared to the theoretically possible 600k combinations of DSM-V.
