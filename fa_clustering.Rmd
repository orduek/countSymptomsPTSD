---
title: "Factor analysis and other clustering methods"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

```{r echo = FALSE, results='hide', message=FALSE, comment=FALSE, warning=FALSE}
## load libraries
require(foreign)
require(tidyverse)
require(ReIns)
require("poweRlaw")
require(lavaan)
```

```{r, echo=FALSE}
dfPCL5 <- read.spss('/home/or/Documents/pcl5_vaData/pcl5_100k/PCL5_130K_FY19.sav', to.data.frame = TRUE)

dfPCL5 <- dfPCL5[,5:24]
dfPCL5 <- na.omit(dfPCL5)
```

```{r echo=FALSE}
dfPCL5_toBinarize <- dfPCL5
for (i in 1:20){
  # becuase under 10 its PCLN01 (02,03) need to add zero so run if
  if (i<10){
  nam <- paste("PCLN0", i, sep = "")  
  }
  else {
    nam <- paste("PCLN", i, sep = "")
  }
  pcl <- paste("PCL", i, sep = "")
  dfPCL5_toBinarize[pcl] <- dplyr::case_when(dfPCL5_toBinarize[nam]<=1 ~ 'NO', dfPCL5_toBinarize[nam]>=2 ~ 'YES')
  
}

# create specific dataframe
dfbigPCL5_Binary2 <- data_frame(dfPCL5_toBinarize[21:40])
countFreqBigPCL5 <- plyr::count(dfbigPCL5_Binary2)
```

## Factor analysis
- Here we try to present the effect of the power law distribution on factor analysis
- We also show it in other graphical manners 

```{r}
# Create new data frame
# join the two so we have frequency next to each individual
dataxCon <- dplyr::full_join(dfPCL5_toBinarize, countFreqBigPCL5, by = c("PCL1" = "PCL1", "PCL2" = "PCL2", "PCL3" = "PCL3", "PCL4" = "PCL4", "PCL5" = "PCL5", "PCL6" = "PCL6", "PCL7" = "PCL7", "PCL8" = "PCL8", "PCL9" = "PCL9", "PCL10" = "PCL10", "PCL11" = "PCL11", "PCL12" = "PCL12", 
 "PCL13" = "PCL13", "PCL14" = "PCL14", "PCL15" = "PCL15", "PCL16" = "PCL16", "PCL17" = "PCL17", "PCL18" = "PCL18", "PCL19" = "PCL19", "PCL20" = "PCL20"))

```

```{r}
dsm5Fac_Con <- '
      Int =~ PCLN01 + PCLN02 + PCLN03 + PCLN04 + PCLN05
      Av =~ PCLN06 + PCLN07
      An =~ PCLN08 + PCLN09 + PCLN10 + PCLN11 + PCLN12 + PCLN13 + PCLN14 
      Hyper =~ PCLN15 + PCLN16 + PCLN17 + PCLN18 + PCLN19 + PCLN20'

```

```{r}
iterateCFA <- function(data, n_itr, filter, sample_size=500) {
  
 # n_itr = 100 # set number of iterations
  results_con = matrix(nrow = n_itr, ncol = 6)#[1:n_itr, 6]
  # set filter (here we take all with freq lower than 10)
  if (filter=='>') {
    print('More than')
    dataN_Con <- filter(data, freq > 10)  
  } else {
    print ('Less than')
    dataN_Con <- filter(data, freq <= 10)  
  }
  
  for (i in 1:n_itr) {
    # filter and sample data
    dfSamp <- sample_n(dataN_Con, sample_size) 
    pcl5Model <- cfa(dsm5Fac_Con, data = dfSamp[,1:20], estimator = "WLSMV")
    results_con[i,] <- fitMeasures(pcl5Model, c("chisq","df","pvalue","srmr","cfi","rmsea"))
    
  }
  # create a dataframe from the matrix
  results <- data.frame(chisq = results_con[,1], df = results_con[,2],
                                               pvalue = results_con[,3], srmr = results_con[,4],
                                               cfi = results_con[,5], rmsea = results_con[,6])
  return(results)
}
```

```{r}
conBigger10 <- iterateCFA(dataxCon, n_itr = 100, filter = '>', sample_size = 300) # failing
MASS::truehist(conBigger10$cfi, xlab = "CFI of all that higher than 10")
# now lower than ten

conSmaller10 <- iterateCFA(dataxCon, n_itr = 100, filter = '<', sample_size = 300)
MASS::truehist(conSmaller10$cfi, xlab = "CFI of all that lower than 10")
summary(conSmaller10)
summary(conBigger10)
```


- The most frequent fits better.
- Lets test the effect of sample size on fitting (i.e. how much will be enough when we sampe most frequent and when we sample less).

### Sample size effects

```{r}
# most frequent
# vector from sample size of 50 to 1000 in steps of 50
size_n <- seq(200,2000,100)
nitr <- 1000
CFI <- c()
CFI_sd <- c()
rmsea <- c()
rmsea_sd <- c()
p <- c()
p_sd <- c()
srmr <- c()
srmr_sd <- c()

for (i in 1:length(size_n)){
  print('sample size {size_n}')
  conBigger10 <- iterateCFA(datax, n_itr = nitr, filter = '>', sample_size = size_n[i]) # failing
  CFI[i] <- median(conBigger10$cfi)
  CFI_sd[i] <- sd(conBigger10$cfi)
  rmsea[i] <- median(conBigger10$rmsea)
  rmsea_sd[i] <- sd(conBigger10$rmsea)
  p[i] <- median(conBigger10$p)
  p_sd[i] <- sd(conBigger10$p)
  srmr[i] <- median(conBigger10$srmr)
  srmr_sd[i] <- sd(conBigger10$srmr)
}

d_above <- data.frame(CFI, CFI_sd, rmsea, rmsea_sd, p, p_sd, srmr, srmr_sd, size_n)
```

```{r}
# - Do the same with the lower tail of the distribution:

CFI_1 <- c()
CFI_sd_1 <- c()
rmsea_1 <- c()
rmsea_sd_1 <- c()
p_1 <- c()
p_sd_1 <- c()
srmr_1 <- c()
srmr_sd_1 <- c()

for (i in 1:length(size_n)){
  print('sample size {size_n}')
  conBigger10 <- iterateCFA(datax, n_itr = nitr, filter = '<', sample_size = size_n[i]) # failing
  CFI_1[i] <- median(conBigger10$cfi)
  CFI_sd_1[i] <- sd(conBigger10$cfi)
  rmsea_1[i] <- median(conBigger10$rmsea)
  rmsea_sd_1[i] <- sd(conBigger10$rmsea)
  p_1[i] <- median(conBigger10$p)
  p_sd_1[i] <- sd(conBigger10$p)
  srmr_1[i] <- median(conBigger10$srmr)
  srmr_sd_1[i] <- sd(conBigger10$srmr)
}
d_below <- data.frame(CFI_1, CFI_sd_1, rmsea_1, rmsea_sd_1, p_1, p_sd_1, srmr_1, srmr_sd_1, size_n)
```

```{r}
# Prepare plots
d_above$group <- c("1")
d_below$group <- c("2")
colnames(d_below) <- colnames(d_above)
dx <- rbind(d_above, d_below)

#Plot CFI
ggplot(data=dx, aes(y=CFI, x=size_n, colour=group, group=group)) +
  geom_point(size = 1.5) + 
  geom_line() +
  geom_errorbar(aes(ymin=CFI-CFI_sd, ymax=CFI+CFI_sd), width=.5, colour="black") +
  xlab("Sample size") +
  ylab("CFI") +
  scale_y_continuous(limits = c(0.90, 1.0)) +
  geom_hline(yintercept=0.95, linetype="dashed", size= 0.3) +
  theme_minimal()


# Plot RMSEA
ggplot(data=dx, aes(y=rmsea, x=size_n, colour=group, group=group)) +
  geom_point(size = 1.5) + 
  geom_line() +
  geom_errorbar(aes(ymin=rmsea-rmsea_sd, ymax=rmsea+rmsea_sd), width=.5, colour="black") +
  xlab("Sample size") +
  ylab("rmsea") +
  scale_y_continuous(limits = c(0.0, 0.06)) +
  geom_hline(yintercept=0.05, linetype="dashed", size= 0.3) +
  theme_minimal()

# Plot p-value
ggplot(data=dx, aes(y=p, x=size_n, colour=group, group=group)) +
  geom_point(size = 1.5) + 
  geom_line() +
  geom_errorbar(aes(ymin=p-p_sd, ymax=p+p_sd), width=.5, colour="black") +
  xlab("Sample size") +
  ylab("p-value") +
  scale_y_continuous(limits = c(0.0, 0.1)) +
  theme_minimal()

# Plot SRMR
ggplot(data=dx, aes(y=srmr, x=size_n, colour=group, group=group)) +
  geom_point(size = 1.5) + 
  geom_line() +
  geom_errorbar(aes(ymin=srmr-srmr_sd, ymax=srmr+srmr_sd), width=.5, colour="black") +
  xlab("Sample size") +
  ylab("srmr") +
  scale_y_continuous(limits = c(0.0, 0.15)) +
  geom_hline(yintercept=0.1, linetype="dashed", size= 0.3) +
  theme_minimal()
  
```
  
- Lastly, all 

```{r}
res2 <- c()
results_con <-  matrix(nrow = 30, ncol = 6)
for (i in 1:length(size_n)){
 # print('sample size {size_n}')
  for (n in 1:30){
    dfSamp <- sample_n(dfPCL5, size_n[i]) 
    pcl5Model <- cfa(dsm5Fac_Con, data = dfSamp[,1:20], estimator = "WLSMV")
    results_con[n,] <- fitMeasures(pcl5Model, c("chisq","df","pvalue","srmr","cfi","rmsea"))
    
  }
  
  res2[i] <- median(results_con[,6])
}

d2 <- data.frame(res2,size_n)
ggplot(data=d2, aes(y=res2, x=size_n)) + geom_jitter() + geom_smooth() +  xlab("rmsea") + theme_minimal()
```



