##############################################################################
#									                                                           #
# 	 The Heterogeneity of Symptoms of Mental Disorders is Heavy-Tailed       #
#                                                                            #
#                         Or Duek & Tobias Spiller                           # 
#                                                                            #
#                       Code Version 0.3 (02.01.2021)                        #
#                                                                            #
#----------------------------------------------------------------------------#
#                                                                            #
#                           MBI: Power law                                   #
#									                                                           #
##############################################################################


###### Table of Contents #####################################################
# Script 1: MBI
#----- 1. Load libraries ----------------------------------------------------#
#----- 2. Import and prepare data -------------------------------------------#
#----- 3. Descriptive -------------------------------------------------------#
#----- 4. Count symptom profiles --------------------------------------------#
#-----  4.1 Binarizing ------------------------------------------------------#
#-----  4.2 Count combinations ----------------------------------------------#
#-----  4.3 Plot ------------------------------------------------------------#
#----- 5. Test distributions ------------------------------------------------#


## General Notes ##
# protector.all = raw data 
# data1 = MBI symptoms of selected participants (age <70, >18)
# data2 = binarized dataframe

###### 1. Load Libraries #####################################################
# Data handling + basic calculations
if(!require("tidyverse")) install.packages("tidyverse")
if(!require("readxl")) install.packages("readxl")
if(!require("foreign")) install.packages("foreign")
if(!require("ReIns")) install.packages("ReIns")

#Power Law
if(!require("poweRlaw")) install.packages("poweRlaw")

#Factor Analysis
if(!require("lavaan")) install.packages("lavaan")
if(!require("psych")) install.packages("psych")

###### 2. Import and prepare data ############################################
#### Import
# protector.all <- read_csv("bp_export_09092019 Kopie.csv")

#### Prepare dataset
### Clean dataset
# Select numeric values (every second row with some adjustments)
protector_values <- protector.all[,seq(1, ncol(protector.all), 2)]
protector_values<- protector_values[,(1:86)] #the 86th colomn does not have an index an values, but only values
protector_values$ID <- seq.int(nrow(protector_values)) # add ID

protector_values2 <- protector.all[,seq(2, ncol(protector.all), 2)]
protector_values2<- protector_values2[,(86:99)]
protector_values2$ID <- seq.int(nrow(protector_values2)) # add ID

#Merge
cleaned.master.df <- merge(protector_values,protector_values2, by= "ID")

#Extract column names
colnames.protect <- colnames(cleaned.master.df)
colnames.protect <- as.data.frame(colnames.protect)

#Rename columns
names.df <- read_excel("names.xlsx") # Cleaned names list
names.df <- t(names.df)
colnames(names.df) = names.df[3, ] # the second row will be the header
colnames(cleaned.master.df) <- colnames(names.df) 

selected_variables_df <- cleaned.master.df %>%
  select("user", "age", "sex", (mbi_1:mbi_16), (ISI_1:ISI_7)) %>% 
  filter(age < 71) # Select 18-70 years old

# Select only entry one per user 
selected_variables_df$duplicate <- duplicated(selected_variables_df$user)
selected_variables_df_dup <- selected_variables_df %>%
  filter(duplicate == FALSE) 

data1 <- selected_variables_df_dup %>% 
  drop_na(mbi_1:mbi_16) %>%
  select("user", "age", "sex", mbi_1:mbi_16, ISI_1:ISI_7)

data1$sex <- as.factor(data1$sex)

data1 <- data1 %>% 
  mutate(totalMBI = rowSums(data1[3:18]),
         totalISI = rowSums(data1[19:26])) 


###### 3. Descriptive #######################################################

summary(data1)
sd(data1$age)
sd(data1$totalMBI)

hist(data1$totalMBI)


###### 4. Count symptom profiles ############################################
######  4.1 Binarized #######################################################
## Binarizing 
# ratings below 3 to 0 (no symptoms) or more to one
data1_binarized <- data1
for (i in 1:16){
  nam <- paste("mbi_", i, sep = "")
  mbi <- paste("MBI_", i, sep = "")
  data1_binarized[mbi] <- dplyr::case_when(data1_binarized[nam]<=2 ~ 'NO', data1_binarized[nam]>=3 ~ 'YES')
  
}

# Create new data frame
data2 <- data1_binarized %>% 
  select(29:44) %>% 
  tibble()

######  4.2 Count combinations ###############################################
### 4.2.1 Count frequency of profiles
data2_counted <- plyr::count(data2[, -1])

# Create sum score of endorsed symptoms
data2_counted$sumsymptoms <- apply(data2_counted, 1, function(x) length(which(x=="YES")))

# Create full dataset
datax <- dplyr::full_join(data1_binarized, data2_counted, by = c("MBI_1" = "MBI_1", "MBI_2" = "MBI_2", "MBI_3" = "MBI_3","MBI_4" = "MBI_4","MBI_5" = "MBI_5",
                                                                 "MBI_6" = "MBI_6", "MBI_7" = "MBI_7", "MBI_8" = "MBI_8","MBI_9" = "MBI_9","MBI_10" = "MBI_10",
                                                                 "MBI_11" = "MBI_11", "MBI_12" = "MBI_12", "MBI_13" = "MBI_13","MBI_14" = "MBI_14","MBI_15" = "MBI_15",
                                                                 "MBI_16" = "MBI_16"))
### 4.2.4 COMBINATIONS
### 4.2.2 Total number of unique symptom combination
nrow(data2_counted) #6640

## Endorsed only once
sum(datax$freq==1) #4109

## Endorsed <= 5
sum(data2_counted$freq<= 5) #6010

## Endorsed <= 100
sum(data2_counted$freq<= 100) #6618

## Endorsed > 100
sum(data2_counted$freq> 100) #22

### 4.2.3 Most common combination 
max(data2_counted$freq) #780

## Assess the symptom profiles
data2_counted <- data2_counted %>% 
  arrange(desc(freq))

print(data2_counted[1,]) # all no
print(data2_counted[2,]) # only mbi10 yes
print(data2_counted[3,]) # all yes

### 4.2.4 INDIVIDUALS

## Median endorsement
med <- median(datax$freq) #12
quantile(datax$freq) # Q1 = 2, Q3= 70, IQR = 68
IQR(datax$freq) # 68

## Endorsed only once
sum(datax$freq==1) #4109
sum(datax$freq==1)/nrow(datax) # 0.169

## Endorsed <= 5
sum(datax$freq<= 5) #9319
sum(datax$freq<= 5)/nrow(datax) # 0.383

## Endorsed <= 50
sum(datax$freq<= 50) #16834
sum(datax$freq<= 50)/nrow(datax) # 0.692

## Endorsed > 100
sum(datax$freq> 100) #4818
sum(datax$freq> 100)/nrow(datax) # 0.198


## Endorsed Top 10 frequencies
top_10 <- (data2_counted$freq[1:10])
cut_min_top_10 <- min(top_10)

sum(datax$freq>= cut_min_top_10) #3269
sum(datax$freq>= cut_min_top_10)/nrow(datax) # 0.134

## Endorsed Top 50 frequencies
top_50 <- (data2_counted$freq[1:50])
cut_min_top_50 <- min(top_50)

sum(datax$freq>= cut_min_top_50) #7005
sum(datax$freq>= cut_min_top_50)/nrow(datax) # 0.288


######  4.3 Plot ##########################################################
### 4.3.1 Plot the 100 most common profiles
freq1_top50  <- data2_counted %>% 
  arrange(freq) %>% 
  top_n(freq, n = 50)

pdf("MBI_.pdf", width=8, height=8)
ggplot(freq1_top50, aes(x=as.factor(1:nrow(freq1_top50)),y=freq)) +
  geom_hline(yintercept = c(10, 50, 100, 250, 500, 800), color = "grey", size = 0.3) +
  geom_bar(stat = "identity",fill = "grey26") +
  xlab("Unique symptom ombinations") + 
  ylab("Number of endorsements") +
  theme_classic() +
  theme(
    axis.text.x = element_blank(),
    axis.ticks = element_blank(),
    plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(breaks=c(10, 50, 100, 250, 500, 800)) +
  ggtitle("The frequency of the hundret most common symptom combinations")
dev.off()  


### 4.3.1 Plot the 100 most common profiles
# datax_counted <- plyr::count(datax$freq)
# colnames(datax_counted) <- c("freq", "count")
# 
# datax_plot <- dplyr::full_join(datax, datax_counted, by = "freq")
# datax_plot$count
# datax_plot$freq
# 
# pdf("MBI_top_100.pdf", width=15, height=8)
# ggplot(datax_plot, aes(x=freq, y=count)) +
#   geom_bar(stat = "identity",fill = "grey26") +
#   xlab("Endorsment of unique combination") + 
#   ylab("Number of individuals") +
#   theme_classic() +
#   ggtitle("") 
# dev.off()  


### 4.3.2 Plot ordered by frequency and symptom sum
# freq1 <- data2_counted %>% 
#   arrange(sumsymptoms, freq)
# 
# freq1 <- freq1 %>%
#   mutate(row_name = row_number())
# 
# pdf("MBI_freq_sum.pdf", width=15, height=8)
# ggplot(freq1, aes(x=as.factor(1:nrow(freq1)),y=freq)) +
#   geom_hline(yintercept = c(10, 50, 100, 250, 500), color = "grey", size = 0.3) +
#   geom_bar(stat = "identity",fill = "grey26") +
#   xlab("Symptom profiles ") + 
#   ylab("Number of endorsements of a given symptom profile") +
#   theme_classic() +
#   theme(
#     axis.text.x = element_blank(),
#     axis.ticks = element_blank(),
#     plot.title = element_text(hjust = 0.5)) +
#   scale_y_continuous(breaks=c(10, 50, 100, 250, 500)) +
#   ggtitle("Distribution of binarized MBI symptom profiles by their frequency")
# dev.off()  

# ### 4.3.3 Plot Pareto Q-Q plots
# pdf("MBI_ParetoQQ.pdf", width=8, height=8)
# ParetoQQ(data = data2_counted$freq, main = "MBI Full sample")
# dev.off()  

###### 5. Test distributions ################################################
#### Prepare
Distribution <- data2_counted$freq

# Power Law
m_pl = displ$new(Distribution)
est_pl = estimate_xmin(m_pl)
m_pl$setXmin(est_pl)
estimate_xmin(m_pl, pars = seq(1.8, 2.5, 0.01))

## Test if power law is possible
bs_p = bootstrap_p(m_pl, no_of_sims = 1000, threads = 5)
# p value
bs_p$p #0.594 -> power law possible

pdf("MBI_PL_estiamtes.pdf", width=8, height=8)
plot(bs_p)
dev.off() 

# Log normal
m_ln = dislnorm$new(Distribution) 
est_ln = estimate_xmin(m_ln)
m_ln$setXmin(est_ln)

# Exponential
m_disexp = disexp$new(Distribution) 
est_disexp = estimate_xmin(m_disexp)
m_disexp$setXmin(est_disexp )

# Poisson
m_pois = dispois$new(Distribution)
est_m_pois = estimate_xmin(m_pois)
m_pois$setXmin(est_m_pois)

# Plot different distrubutions
options(scipen=5)
pdf("MBI_qq_distributions.pdf", width=8, height=8)
plot(m_pl, main="Distribution of symptom combinations",
     xlab="Number of endorsements", ylab="CDF",panel.first = grid(col = "grey80"))
text(x=200, y=0.5, "Power-Law  ",col="2", font=2, cex=0.8)
text(x=200, y=0.39, "Log-Normal ",col="3", font=2, cex=0.8)
text(x=200, y=0.3, "Exponential ",col="4", font=2, cex=0.8)
lines(m_pl, col = 2) 
lines(m_ln, col = 3) 
lines(m_disexp, col = 4)
lines(m_pois, col = 5)
dev.off()


### Test if power law or log-normal distribution fits better
m_ln$setXmin(m_pl$getXmin())
est_m_ln = estimate_pars(m_ln)
m_ln$setPars(est_m_ln)

comp = compare_distributions(m_pl, m_ln)
comp$p_two_sided #not sig: inconclusive
comp$p_one_sided #not sig: inconclusive


